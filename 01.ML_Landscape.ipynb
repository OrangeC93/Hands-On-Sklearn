{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1. The Machine Learning Landscape\n",
    "- The first ML application that really became maintream and improved the lives of 100s of millions of people took over in the 1990s, The Spam Filter.\n",
    "- We will take a look at the map and learn about the most notable regions of ML\n",
    "    - Supervised versus Unsupervised Learning\n",
    "    - Online versus batch learning\n",
    "    - Instance-based versus model-based learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Machine Learning?\n",
    "- Machine Learning is the science (and art) of programming computers so that they can learn from data.\n",
    "- Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed. — Arthur Samuel (1959)\n",
    "- A computer program is said to learn from experience $E$ with respect to some task $T$ and some performance measure $P$, if its performance on $T$, as measured by $P$, improves with experience $E$. — Tom Mitchell (1997)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why use Machine Learning?\n",
    "1. Make rules\n",
    "2. Write Algorithm\n",
    "3. If Algorithm performs well $\\to$ deploy. If not, go to (1).\n",
    "\n",
    "    - If the problem is complex, you'll likely endup with a long list of rules that are hard to maintain to scale to other similar problems.\n",
    "    - A machine learning approach would be much shorter, easier to maintain, and in many cases, more accurate. \n",
    "    - Machine Learning can help humans learn.\n",
    "        - You can train an algorithm on a large dataset, then inspect the algorithm for feature importance to gain a better understanding of the relation between the data & the problem.\n",
    "        - This is called data mining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Applications\n",
    "- Image Classification: typically performed using convolutional neural networks\n",
    "- Semantic segmentation: when we want to classify each pixel in an image, example is brain tumor detection (will give us shape and location)\n",
    "- Natural Language Processing: & More specifically, text classification, which can be performed using RNNs, CNNs, or Transformers.\n",
    "- NLP: Automatic Text Summarization\n",
    "- Chatbot: Involves many NLP tasks such as Natural Language Understanding (NLU) and Question-Answering.\n",
    "- Forecasting your company's revenue next year: a regression task that can be tackled using multiple algorithms such as\n",
    "    - Linear Regression\n",
    "    - Polynomial Regression\n",
    "    - SVM\n",
    "    - Random Forest\n",
    "- Artificial Neural Networks\n",
    "- If sequences of past performance indicators are involved, we can use RNNs, CNNs or Transformers.\n",
    "- Making your app react to voice commands: This is speech recognition, can be tackled by recognizing the incoming audio signals using RNNs, CNNs or Transformers.\n",
    "- Detecting credit card fraud: this is anomaly detection.\n",
    "- Segmenting clients based on their purchases so you can design targeted more effective marketing campaigns, a Clustering problem\n",
    "- Representing a complex, high-dimensional dataset in a diagram: this is data visualization, typically using dimensionality reduction algorithms such as PCA.\n",
    "- Recommending a product based on the client's purchases history: this is a recommender system, where you can feed in the sequence of purchases to an artificial neural network to predict the next purchase.\n",
    "- Building an intelligent bot for a game: this is usually solved using reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Machine Learning Systems\n",
    "\n",
    "- Supervised/Unsupervised Learning\n",
    "    - Machine learning algorithms can be classified according to the amount of supervision they get during training\n",
    "    - They are 4 major categories\n",
    "        - Supervised Learning\n",
    "            - The training set you feed into the supervised learning algorithm contains the targets/labels/desired predictions.\n",
    "            - Most supervised learning tasks fall under two umbrellas: Classification/Regression\n",
    "            - Some regression-based models are used for classification as well, such as `Logistic Regression` which outputs a probability $\\in [0,1]$\n",
    "            - Here are some of the most important supervised learning algorithms\n",
    "                - K-nearest Neighbors\n",
    "                - Linear Regression\n",
    "                - Logistic Regression\n",
    "                - Decision Trees and Random Forests\n",
    "                - Artificial Neural Networks\n",
    "                - Naive Bayes\n",
    "        - Semi-supervised Learning\n",
    "        - Reinforcement Learning\n",
    "        - Unsupervised Learning\n",
    "            - The data is unlabeled, the system is trying to learn without a teacher.\n",
    "            - Here are some unsupervised learning algorithms\n",
    "                - Clustering\n",
    "                    - K-means\n",
    "                    - DBSCAN\n",
    "                    - Hirerchical Cluster Analysis\n",
    "                - Anomaly Detection\n",
    "                    - one-class SVM\n",
    "                    - Isolation Forest\n",
    "                - Visualization & Dimensionality Reduction: the goal is to compress/simplify the data without losing too much information (1 way to do it is to merge highly correlated features)\n",
    "                    - Principal Component Analysis: PCA\n",
    "                    - t-distributed stochastic Neighbor Embedding: T-SNE\n",
    "                    - Autoencoders\n",
    "                    - Kernel PCA\n",
    "                    - Local Linear Embedding (LLE)\n",
    "                - Association rule learning: find interesting relations between attributes\n",
    "                    - Apriori\n",
    "                    - Eclat\n",
    "        - Semi-supervised Learning\n",
    "            - You have partially-labeled data\n",
    "            - The goal is to not classify the unlebeled ones but to use them around the labeled points as helpers to solve the task\n",
    "            - Most semi-supervised learning algorithms are a combination of unsupervised and supervised learning algorithms\n",
    "        - Reinforcement Learning\n",
    "            - RL is a very different beast.\n",
    "            - An agent observes the environment, selects an action, gets a reward, and updates its policy.\n",
    "- Batch & Online Learning\n",
    "    - Another criterion to classify a machine learning algorithm is whether it learns from an incoming stream of data or not.\n",
    "    - Batch Learning\n",
    "        - In batch learning, the model is incapable of incrementally learning, It first learns from all of the available data offline, and then get deployed to produce predictions without feeding it any new data points.\n",
    "        - Another name of batch learning is Offline Learning.\n",
    "    - Online Learning\n",
    "        - In online learning, you train data incrementally by continuously feeding it data instances as they come.\n",
    "            - Either individually or in small groups of instances called *mini-batches*.\n",
    "        - Each learning step is fast and cheap, so the system can learn as data comes, on the fly.\n",
    "        - Online learning is great for system that receive data in a continuous flow.\n",
    "        - Think about Online learning as incremental learning.\n",
    "        - One important aspect of online learning is how fast the learning algorithm should adapt to new data points\n",
    "            - With a big learning rate — the model tends to forget past data and lean heavily towards new data points.\n",
    "            - With a small learning rate — the model tends to slightly adapt to new data points but keeps its knowledge on old data points mostly intact.\n",
    "        - A big challenge with online learning algorithms is that they can be damaged with bad incoming data points and clients will notice that on the fly\n",
    "            - To mitigate this, you can:\n",
    "                - Closely monitor the system through performance metrics, turn off online learning or revert back to a previous model state.\n",
    "                - Clean the data before feeding it to the model by scanning it for anomaly/outlier detection\n",
    "- Instance-based versus Model-based Learning\n",
    "    - One other way to categorize machine learning algorithms is how they generalize\n",
    "    - There are two approaches to generalization: instance-based approaches and model-based approaches.\n",
    "    - Instance-based Learning\n",
    "        - Similarity-based comparison, a new data point would be classified based on its similarity to the target group in the training set, this would require a measure of similarity.\n",
    "    - Model-based Learning\n",
    "        - Another way to make predictions is to build a model for each class of data points and then use the model to classify a new data point (from the validation/test/production environment).\n",
    "        - What follows is an example of model-based learning using linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Challenges of Machine Learning\n",
    "\n",
    "- The two things that can go wrong are: Bad learning algorithm, Bad data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Insufficient quantity of training data\n",
    "    - Even for very simple ml algorihtms, it takes thousands of examples for it to recognize Cat/Dog.\n",
    "    - A famous paper showed the many algorithms, ranging from very simple ones to complex, perform relatively the same when given enough data.\n",
    "        - The authors argued that we should reconsider where companies should invest their money, in algorithms development or in data corpuses engineering.\n",
    "- Non-representative training data\n",
    "    - In order to generalize well, It's important that your training data be representative of the data that you want to use the system for\n",
    "    - If the sample is too small, you will have sampling noise.\n",
    "    - But even large samples can be non-representative if the sampling method is flawed, this is called **sampling bias**.\n",
    "        - Example of sampling bias — Non-response bias.\n",
    "- Poor quality data\n",
    "    - Obviously, if your training data is full of outliers, errors, and noise, it will make it harder for the algorithm to detect the underlying patterns, resulting in a bad model.\n",
    "    - It's often well worth the time to sit down and properly clean and investigate your data before doing any modeling.\n",
    "    - Example of data cleaning\n",
    "        - If some instances (data points/rows) are clearly outliers, it may be logical to just discard them or manually fix them.\n",
    "        - if some instances are missing a few features, you have multiple options: Discard the instances, fill them with median, train two models (one w/ features and one w/o it).\n",
    "- Irrelevant features\n",
    "    - You system will only learn if your data contains many relevant features and not so many irrelevant ones.\n",
    "    - A critical part of the success of a machine learning project is what's called **feature engineering** or coming up with features that would produce a quality model, it contains two steps:\n",
    "        - Feature selection: selecting the most useful features to train on.\n",
    "        - Feature Extraction: adding new features based of the existing ones.\n",
    "        - Creating new features by gathering new data.\n",
    "- Overfitting the training data\n",
    "    - Say you visited a foreign country and a taxi driver ripped you off, that is overfitting, we do it all the time and we adjust our beliefs as we get more data.\n",
    "    - Machines, unfortunately, do it as well. \n",
    "    - Overfitting means the predictive system performs well on the training data but fails to generalize.\n",
    "    - Complex models such as deep neural networks tend to memorize training data noise or even the data sample itself if its small enough.\n",
    "    - Possible solutions\n",
    "        - Select a model with fewer weights/parameters to constrain its predictive power so that it can use only the strongest present patterns\n",
    "        - Gather more training data\n",
    "        - Reduce the noise in the training data, fix errors and eliminate outliers.\n",
    "    - Constraining a model to make it simpler and fighting overfitting is called **regularization**.\n",
    "    - In the case a a simple linear model, it has two degrees of freedom (2 parameters)\n",
    "    - If we let the algorithm change one parameter's values freely but have a set interval around parameter 2, it will have a between 1 and 2 degree of freedom.\n",
    "    - You want a good balance between keeping the model as simple as possible while giving the model the ability to capture out of training data patterns.\n",
    "    - Regularization can be controlled using hyperparameters, hyperparameters describe how the model should learn, not the parameters of the model itself.\n",
    "- Underfitting the Training Data\n",
    "    - Underfitting is the opposite of overfitting\n",
    "    - It occurs when your model is too simple to capture the underlying structure of the training data \n",
    "    - Here are solutions to the problem\n",
    "        - Select a more powerful model, with more parameters\n",
    "        - Feed better features to the learning algorithm (feature engineering)\n",
    "        - Reduce the constraints on the model (reduce regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing & Validating\n",
    "\n",
    "- You evaluate your model by splitting your data into two sets: training and testing data sets.\n",
    "- You only care about out-of-training error, or generalization error, as it is representative of the model's performance in a production environment.\n",
    "- If your training error is low but your testing error is high, this means that you model is overfitting.\n",
    "- It's common to use 80% of the data for training and the remaining 20% for testing.\n",
    "    - But it's dependent on the size of the original data set, the bigger it is, the less percent you can take as a testing set.\n",
    "- Hyper-parameter tuning & model selection\n",
    "    - If you fine-tune regularization parameters on the test set, you are sort of overfitting to it, so you need another data set for Hyper-parameter tuning, called **validation set**.\n",
    "    - The validation set should be set aside from the training set. \n",
    "    - After the holdout validation process (fine-tuning the hyper-parameters) you traing the model on the full training set (with validation) & evaluate on the test set.\n",
    "    - A solution to setting aside a large validation set is to perform repeated cross-validation.\n",
    "        - It has a drawback though, you have to train the model N-repetitions.\n",
    "- Data Mismatch\n",
    "    - The validation set & the test set must be as representative as possible for the data you will use in production.\n",
    "    - One solution to this when you have a broad range of data is to manually select cases that will show up in production as (validation/test) sets.\n",
    "    - One Problem is that if the algorithm is performing poorly on the validation set you won't know if the cause is overfitting or if the training set isn't good for the task at hand.\n",
    "        - A solution to this is to introduce another validation set, called 'train-dev' set.\n",
    "        - After training you will validate the model on both `train-dev` & validation sets.\n",
    "            - If evaluation is good on `train-dev` & bad on `validation`, this means that the data is not good for the task at hand.\n",
    "            - If evaluation is bad on `train-dev` & bad on `validation`, this means overfitting or the algorithm/overall data is not good.\n",
    "- No Free Lunch Theorem\n",
    "    - **A model is a simplified version of the observations**.\n",
    "        - The simplifications are meant to discard noise and capture generalizable useful patterns that will be captured in production.\n",
    "    - To decide what information to discard and what to keep, you must make assumptions.\n",
    "    - For example, a linear model assumes that the relation between the input & output is fundamentally linear.\n",
    "        - & the distance between the model line and the observations is essentially **noise**.\n",
    "    - **If you make no assumptions about the data, than there is no need to prefer one model over another**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercices\n",
    "\n",
    "**1. How would you define Machine Learning?**\n",
    "- Machine Learning is the ability to learn from data without being explicitly programmed.\n",
    "\n",
    "**2. Can you name four types of problems where is shines?**\n",
    "- Image classification, Voice Recognition, Semantic Segmentation, Sentiment Analysis.\n",
    "\n",
    "**3. What is a labeled training set?**\n",
    "- In the context of supervised learning, a labeled training set is a data set with available targets, what you want to predict is known before training.\n",
    "- Example: a training set composed of images of cats or dogs and the corresponding **label** (cat/dog) for each of the images.\n",
    "\n",
    "**4. What are the two most common supervised tasks?**\n",
    "- Classification (where the target is categorical in nature) & Regression (where the labels are continuous in nature).\n",
    "\n",
    "**5. Can you name four common unsupervised tasks?**\n",
    "- Clustering, Anomaly detection, Visualization, dimensionality reduction.\n",
    "\n",
    "**6. What type of machine learning algorithm would you use to allow a robot to walk in many paths in an unknown terrain?**\n",
    "- Reinforcement learning.\n",
    "\n",
    "**7. What type of algorithm would you use to segment your customers into multiple groups?**\n",
    "- An unsupervised clustering algorithm like: K-means, DBSCAN.\n",
    "\n",
    "**8. Would you frame the problem of spam detection as a supervised learning or an unsupervised learning problem?**\n",
    "- It a supervised learning problem.\n",
    "\n",
    "**9. What is an online learning system?**\n",
    "- An online learning system continues to learn from new data after being deployed in production, in contrast to a batch learning model which would stop learning after the initial training process.\n",
    "\n",
    "**10. What is out-of-core learning?**\n",
    "- *We use out-of-core learning algorithms when the training data can't fit ina computer's RAM.*\n",
    "\n",
    "**11. What type of learning algorithm relies on a similarity measure to make predictions?**\n",
    "- Instance-based models, an example of that is K-nearest neighbors.\n",
    "\n",
    "**12. What is the difference between a model's parameters and a learning algorithm's hyper-parameter?**\n",
    "- A model's parameters are the knobs that, collectively, store the learned knowledge of the model, also called weights, they are continuously changed during training to minimize a cost function. Examples are a & b in a y = ax + b linear model.\n",
    "- A learning algorithm's hyper-parameter describes how the algorithm should learn and control the predictive power of the model, example is the learning rate, number of layers in a NN, regularization, batch size, they are set before training and aren't changed during training.\n",
    "\n",
    "**13. What do model-based algorithms search for?**\n",
    "- A decision boundary.\n",
    "\n",
    "**14. What is the most common strategy they use to succeed?**\n",
    "- They minimize a cost function that describe the distance between the predictions outputted by the model and the real target values.\n",
    "\n",
    "**14. How do they make predictions?**\n",
    "- They start with a set of initial parameters, make predictions based on the input & their parameters, then adjust their parameters to minimize cost.\n",
    "\n",
    "**15. Can you name 4 of the main challenges in machine learning?**\n",
    "- Algorithmic challenges — Model Overfitting, Model Underfitting.\n",
    "- Data challenges — Data mismatch, Noisy data.\n",
    "\n",
    "**16. If your model performs great on the training data but fails on the test data, What is happening?**\n",
    "- Overfitting, the model starts memorizing noise present on the training data to further minimize the cost function. \n",
    "\n",
    "**17. Can you name 3 possible solutions?**\n",
    "- Regularization, Adding more data, Simplifying the model.\n",
    "\n",
    "**18. What is a test set? & Why you would want to use it?**\n",
    "- The whole data set is usually split into training data (~80%) and test data (~20%), we use test data to evaluate the generalizability of the model beyond the training data set.\n",
    "\n",
    "**19. What is the purpose of a validation set?**\n",
    "- A validation set is used to fine-tune the models' hyper-parameters, what is called manual training, and leave the test set for the final evaluation.\n",
    "\n",
    "**20. What is the `train-dev` set?, When do you use it? & How do you use it?**\n",
    "- the `train-dev` is a validation set that is taken from a broad training set after performing the train/validation/test split.\n",
    "- We use it when we have a broad training data set (ex. images of all animals) but specific validation/test set (zoo animal pics taken with mobile phones) and we want to correctly interpret the model's evaluation.\n",
    "- We train the model on the training data set, we evaluate on `train-dev` and `validation`, if model performs badly on both, we have an overfitting case, if the model performs good in `train-dev` and badly on `validation` we have a data mismatch we the learning doesn't generalize to our specific production data.\n",
    "\n",
    "**21. What can go wrong if you tune hyper-parameters using the test set?**\n",
    "- I can accidentaly overfit the test set as well by manually finding hyper-parameters that perform well on the test set but doesn't generalize to production data.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
