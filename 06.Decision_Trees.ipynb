{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6. Decision Trees\n",
    "> These are the classic, and most intuitive structures in machine learning. Where thresholds are developed on features, and these lead to further decision points on subsequent features, leading to a classification. These can be loosely used for regression too! One of the great benefits is a simple explanation of the algorithm's conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this Chapter, we will start by discussing how to train, validate, and make predictions with decision trees.\n",
    "- Then we will go through the CART training algorithm used by Scikit-Learn, we will discuss how to regularize trees and use them in regression tasks.\n",
    "- Finally, we will discuss some of the limitations of decision trees.\n",
    "\n",
    "## Training & Visualizing a Decision Tree\n",
    "\n",
    "- To understand decision trees, let's start by building one and taking a look at its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:,2:]\n",
    "y = iris.target\n",
    "X.shape, y.shape\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can visualize the decision tree by using the `export_graphiz()` method to export a graph representation file then taking a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(tree_clf, \n",
    "                out_file='iris_tree.dot', \n",
    "                feature_names=iris.feature_names[2:],\n",
    "                class_names=iris.target_names,\n",
    "                rounded=True,\n",
    "                filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: dot: command not found\r\n"
     ]
    }
   ],
   "source": [
    "! dot -Tpng models/06/iris_tree.dot -o static/imgs/iris_tree.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "- To classify a new data point, you start at the root node of the graph (on the top), and you answer the binary questions and you reach the end leaf.\n",
    "    - That end leaf represents your class.\n",
    "        - It's really that simple!\n",
    "- One of the many qualities of decision trees is that they require very little data preparation.\n",
    "    - **In fact, they don't require feature scaling or centering at all!**\n",
    "- A node's `samples` attribute counts how many training instances are sitting on the node.\n",
    "- A node's `value` attribute tells you have many instances of each class are setting on the node.\n",
    "- A node's `gini` attribute measures the nodes impurity (pure == 0)\n",
    "    - The following equation shows how the training algorithm computes the gini scores of the ith node:\n",
    "\n",
    "        $$G_i=1-\\sum_{k=1}^n{p_{i,k}}^2$$\n",
    "\n",
    "    - Where $p_{i,k}$ is the ratio of class $k$ instances among the training instances in that particular node.\n",
    "        - In our case: $k \\in \\{1,2,3\\}$.\n",
    "- Scikit-learn uses the CART algorithm, which produces only binary trees\n",
    "    - Non-leaf nodes only have two children\n",
    "- However, other algorithms such as ID3 can produce decision trees with nodes that have more than 2 children.\n",
    "- The following figure shows the decision boundaries of our decision tree\n",
    "    - Decision Trees tend to create lines/rectangles/boxes/.. and split the feature space linearly but iteratively.\n",
    " \n",
    "<div style=\"text-align:center\"><img style=\"width:50%\" src=\"static/imgs/decision_tree_boundaries.png\"></div>\n",
    "\n",
    "- Decision Trees are intuitive, and their predictions are easily interpretable.\n",
    "    - These types of models are called **white box** models.\n",
    "- In contrast, as we will see, Random Forests and Neural Networks are generally considered Black Box models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Class Probabilities\n",
    "\n",
    "- A decision tree can also estimate the probability that a certain instance belongs to a certain class.\n",
    "    - It just returns the ratio of that class over the sum of all instances in the leaf.\n",
    "- Let's check this in scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict_proba([[5, 1.5]])\n",
    "tree_clf.predict([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Interesting insight: you'll get the same probability as long as you're in a certain leaf box\n",
    "    - It doesn't matter if your new data point gets closer to the decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CART Training Algorithm\n",
    "\n",
    "- Scikit-Learn uses the Classification and Regression Tree (CART) algorithm to train decision trees (also called \"growing\" trees).\n",
    "- The algorithm works by first splitting the training set by feature $k$ and threshold $t_k$.\n",
    "- How does it choose $k$ and $t_k$?\n",
    "    - It searches for $(k,t_k)$ that produce the purest subsets.\n",
    "        - Weighted by their size.\n",
    "- The following gives the loss function that CART tries to minimize:\n",
    "\n",
    "$$J(k,t_k)=\\frac{m_{left}}{m}G_{left} + \\frac{m_{right}}{m}G_{right}$$\n",
    "\n",
    "- Where:\n",
    "    - $G_{left/right}$ measures the resulted impurity in the left/right subsets.\n",
    "    - $m_{left/right}$ correspond to the number of instances in the left/right subsets.\n",
    "- Once the CART algorithm successfully split the initial training data into two subsets, it does the same thing to both subsets.\n",
    "- It stops recursing once it reaches the maximum allowed tree depth (the `max_depth` hyper-parameter).\n",
    "    - Or if it cannot find a split that reduces impurity.\n",
    "- A few other hyper-parameters control stopping like:\n",
    "    - `min_samples_split`, `min_samples_leaf`, `min_weight_fraction_leaf`, `max_leaf_nodes`.\n",
    "- The CART algorithm is greedy in the sense that it doesn't care if its current split will lead to an optimal downstream leaf.\n",
    "    - It only cares about finding the best possible split at the current leaf.\n",
    "    - In that sense, it doesn't necessarily result in an optimal solution.\n",
    "- Unfortunately, finding the optimal tree is known to be an **NP-Complete** problem with a complexity of $O(exp(m))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Complexity\n",
    "\n",
    "- Making a prediction requires us to go from the root the final leaf.\n",
    "- Decision trees are approximately balanced, so traversing the decision tree require going through roughly $O(log_{2}(m))$.\n",
    "- Since each node requires check the value of only one feature, the overall inference running time is $O(log_{2}(m))$.\n",
    "    - Independent of the number of features.\n",
    "        - So predictions are really fast, even when dealing with a large number of features.\n",
    "- The training algorithm compares all features (except if `max_features` is set) on all samples at each node.\n",
    "- Comparing all features at all samples at each node results in a training complexity of $O(n \\times mlog_2(m))$.\n",
    "    - For small training sets (less than a few thousands), scikit-learn can speed up training by presorting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Impurity or Entropy?\n",
    "\n",
    "- In information theory, entropy is zero when all messages are identical.\n",
    "- In ML, entropy is often used as an impurity measure.\n",
    "- A set's entropy is zero when **it contains instances of only one class**.\n",
    "- The following formula shows the entropy at node $i$:\n",
    "\n",
    "$$H_i=-\\sum_{k=1}^{n}p_{i,k}log_2(p_{i,k})$$\n",
    "\n",
    "- There's no big difference between using Gini or Entropy to measure impurity.\n",
    "    - Gini impurity is slightly faster to compute.\n",
    "    - When they differ, Entropy tends to produce more balanced trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization Hyperparameters\n",
    "\n",
    "- **Decision Trees make very few assumptions about the training data**.\n",
    "- If left unconstrained and because of its flexibility, a decision tree will adapt itself to perfectly fit the training data.\n",
    "    - Naturally leading to overfitting.\n",
    "- Such a model is often called a *non-parameteric model* because the number of parameters is not determined before training.\n",
    "- You can at least restrict the maximum depth of the decision tree.\n",
    "- Other regularization hyper-parameters include:\n",
    "    - `min_samples_split`: The minimum number of samples a node must have for it to split.\n",
    "    - `min_samples_leaf`: The minimum number of samples a leaf must have.\n",
    "    - `min_weight_fraction_leaf`: `mean_samples_leaf` as a fraction.\n",
    "    - `max_leaf_nodes`: the maximum number of leaf nodes.\n",
    "    - `max_features`: The maximum number of features that are evaluated for any split.\n",
    "- The following figure shows two decision trees trained on the same moon dataset, the left one represent an unconstrained trained decision tree, and the right one is regularized using the `min_samples_leaf` hyper-parameter:\n",
    "\n",
    "<div style=\"text-align:center\"><img style=\"width:50%\" src=\"static/imgs/regularized_tree.png\"></div>\n",
    "\n",
    "```\n",
    "For instance, if min_samples_split = 5, and there are 7 samples at an internal node, then the split is allowed. But let's say the split results in two leaves, one with 1 sample, and another with 6 samples. If min_samples_leaf = 2, then the split won't be allowed (even if the internal node has 7 samples) because one of the leaves resulted will have less then the minimum number of samples required to be at a leaf node.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "- Decision Trees are also capable of performing regression tasks.\n",
    "- Let's try it using scikit-learn:\n",
    "- First we want to generate a noisy quadratic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1251d4518>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.linspace(start=0, stop=1, num=500)\n",
    "y = (X-0.5)**2 + np.random.randn(500)/50.\n",
    "\n",
    "plt.scatter(X, y, s=1.5, c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg.fit(X[..., None], y[..., None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(tree_reg, \n",
    "                out_file='reg_tree.dot', \n",
    "                feature_names=['X'],\n",
    "                class_names=['y'],\n",
    "                rounded=True,\n",
    "                filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img style=\"width:50%\" src=\"static/imgs/reg_tree.png\"></div>\n",
    "\n",
    "- This tree looks very similar to the classification tree we built earlier.\n",
    "- The main difference is that instead of predicting a class for each node, it predicts a value.\n",
    "- the prediction represents the average target value for the group in the leaf.\n",
    "- As you increase the `max_depth` hyper-parameter, you provide the regression tree with more flexibility, the following showcases tree predictions in red:\n",
    "\n",
    "<div style=\"text-align:center\"><img style=\"width:66%\" src=\"static/imgs/regression_trees.png\"></div>\n",
    "\n",
    "- The CART algorithm works almost the same as before, but instead of searching for a split that minimizes impurity, it searches for a split that produce balanced samples per leaf and minimize $MSE$.\n",
    "- We show the cost function that the algorithm tries to minimize:\n",
    "\n",
    "$$J(k,t_k)=\\frac{m_{left}}{m}MSE_{left} + \\frac{m_{right}}{m}MSE_{right} \\\\ MSE=\\frac{1}{m}\\sum_{i=1}^{m}(\\hat{y}_{i}-y_{i})^{2}$$\n",
    "\n",
    "- Just like classification, regression trees are prone to overfitting the training data, without any regularization, we endup with the plot on the left, and setting `min_samples_leaf=10` produce a much reasonable model:\n",
    "\n",
    "<div style=\"text-align:center\"><img style=\"width:66%\" src=\"static/imgs/regularizing_trees.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instability\n",
    "\n",
    "- Decision Trees have a few limitations:\n",
    "    - Decision Trees love orthogonal decision boundaries.\n",
    "        - Which makes them sensitive to training set rotation.\n",
    "            - One way to limit this problem is to use PCA (Principal Component Analysis) which often results in a better orientation of the training data.\n",
    "    - Decision Trees are sensitive to small variations in the training data.\n",
    "        - In fact, because scikit-learn uses stochastic optimization, you might get different models for the same training dataset.\n",
    "            - Random Forests can solve this problem by averaging incoming prediction from many decision trees.\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
